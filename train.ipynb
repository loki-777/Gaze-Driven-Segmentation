{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "import tqdm\n",
    "import os, glob\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "import numpy as np\n",
    "from albumentations import Compose, Normalize, Resize, HorizontalFlip\n",
    "import matplotlib.pyplot as plt\n",
    "import monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazeSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, gaze_paths, transform=None, use_gaze=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.gaze_paths = gaze_paths\n",
    "        self.transform = transform\n",
    "        self.use_gaze = use_gaze\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx], 0).astype(np.float64) / 255\n",
    "        mask = cv2.imread(self.mask_paths[idx], 0).astype(np.float64).T / 255\n",
    "        gaze_seq = np.load(self.gaze_paths[idx])\n",
    "        gaze = self.prepare_gaze(gaze_seq)\n",
    "\n",
    "        fused_input = np.zeros((1024, 1024, 2))\n",
    "        fused_input[:, :, 0] = image[:]\n",
    "        fused_input[:, :, 1] = gaze[:]\n",
    "        expanded_mask = np.zeros((1024, 1024, 2))\n",
    "        expanded_mask[:, :, 0] = mask[:]\n",
    "        expanded_mask[:, :, 1] = mask[:]\n",
    "\n",
    "        # transforms\n",
    "        if self.use_gaze:\n",
    "            transformed = self.transform(image=fused_input, mask=expanded_mask)\n",
    "            mask = np.transpose(transformed[\"mask\"], (2, 0, 1))\n",
    "            mask = np.expand_dims(mask[0, :, :], 0)\n",
    "        else:\n",
    "            image = np.expand_dims(image, 2)\n",
    "            mask = np.expand_dims(mask, 2)\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            mask = np.transpose(transformed[\"mask\"], (2, 0, 1))\n",
    "            \n",
    "        \n",
    "        image = np.transpose(transformed[\"image\"], (2, 0, 1))\n",
    "        \n",
    "        return np.expand_dims(image, 0), np.expand_dims(mask, 0)\n",
    "    \n",
    "    def prepare_gaze(self, gaze_seq):\n",
    "        gaze_seq = [(int(g[0]*1024), int(g[1]*1024), int(g[2])) for g in gaze_seq]\n",
    "        gaze = np.zeros((1024, 1024))\n",
    "        for point in gaze_seq:\n",
    "            point = list(point)\n",
    "            center = point[:2][::-1]\n",
    "            radius = point[-1]*20\n",
    "            color = (255, 255, 255)\n",
    "            thickness = -1\n",
    "            cv2.circle(gaze, center, radius, color, thickness)\n",
    "        return gaze\n",
    "\n",
    "\n",
    "class SegmentationDataModule(L.LightningDataModule):\n",
    "    def __init__(self, dataset_dir, transform=None, batch_size=8, num_folds=5, use_gaze=False):\n",
    "        super().__init__()\n",
    "        self.image_paths = glob.glob(os.path.join(dataset_dir, \"images\", \"*\"))\n",
    "        self.mask_paths = glob.glob(os.path.join(dataset_dir, \"masks\", \"*\"))\n",
    "        self.gaze_paths = glob.glob(os.path.join(dataset_dir, \"gaze\", \"*\"))\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.num_folds = num_folds\n",
    "        self.use_gaze = use_gaze\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Stratified K-Fold Split\n",
    "        labels = [(cv2.imread(mask_path, 0) / 255).max() for mask_path in self.mask_paths]\n",
    "        skf = StratifiedKFold(n_splits=self.num_folds)\n",
    "        self.folds = list(skf.split(self.image_paths, labels))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self, fold_idx):\n",
    "        train_idx, _ = self.folds[fold_idx]\n",
    "        train_dataset = Subset(GazeSegmentationDataset(self.image_paths, self.mask_paths, self.gaze_paths, self.transform, self.use_gaze), train_idx)\n",
    "        return train_dataset, DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self, fold_idx):\n",
    "        _, val_idx = self.folds[fold_idx]\n",
    "        val_dataset = Subset(GazeSegmentationDataset(self.image_paths, self.mask_paths, self.gaze_paths), val_idx)\n",
    "        return val_dataset, DataLoader(val_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, model_params=None):\n",
    "        super(UNET, self).__init__()\n",
    "        if model_params is None:\n",
    "            self.model = monai.networks.nets.UNet(\n",
    "                spatial_dims=2,\n",
    "                in_channels=2,\n",
    "                out_channels=1,\n",
    "                channels=(16, 32, 64, 128, 256),\n",
    "                strides=(2, 2, 2, 2)\n",
    "            )\n",
    "        else:\n",
    "            self.model = monai.networks.nets.UNet(\n",
    "                spatial_dims=model_params[\"spatial_dims\"],\n",
    "                in_channels=model_params[\"in_channels\"],\n",
    "                out_channels=model_params[\"out_channels\"],\n",
    "                channels=model_params[\"channels\"],\n",
    "                strides=model_params[\"strides\"]\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLightningModule(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.dice_loss = monai.losses.GeneralizedDiceLoss(sigmoid=True)\n",
    "        self.dice_metric = monai.metrics.DiceMetric()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.type(torch.torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.torch.cuda.FloatTensor)\n",
    "\n",
    "        y_hat = self.model(X)\n",
    "        loss = self.dice_loss(y_hat, y)\n",
    "\n",
    "        self.log(\"train/loss\", loss, sync_dist=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.type(torch.torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.torch.cuda.FloatTensor)\n",
    "\n",
    "        y_hat = self.model(X)\n",
    "        val_loss = self.dice_loss(y_hat, y)\n",
    "\n",
    "        y_hat = F.sigmoid(y_hat)\n",
    "        y_hat = 0 + (y_hat > 0.5)\n",
    "        y = 0 + (y > 0.5)\n",
    "        val_metric = self.dice_metric(y_pred=y_hat, y=y)\n",
    "\n",
    "        self.log(\"val/loss\", val_loss, sync_dist=True)\n",
    "        self.log(\"val/metric\", val_metric, sync_dist=True)\n",
    "\n",
    "        return val_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"pneumothorax\"\n",
    "\n",
    "gpus_available = torch.cuda.device_count()\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(height=224, width=224),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.5,), std=(0.5,)),\n",
    "])\n",
    "data_module = SegmentationDataModule(\"pneumothorax\", transform=transform, use_gaze=False)\n",
    "data_module.setup()\n",
    "\n",
    "model = UNET()\n",
    "lightning_module = CustomLightningModule(model)\n",
    "\n",
    "# Train the model using 5-fold cross-validation\n",
    "for fold_idx in range(5):\n",
    "    print(f\"Training fold {fold_idx+1}/5\")\n",
    "    wandb_logger = WandbLogger(project=\"GAZE\", name=f\"Fold-{fold_idx}\")\n",
    "    trainer = L.Trainer(\n",
    "        devices=gpus_available,\n",
    "        accelerator=\"gpu\",\n",
    "        strategy=\"ddp\",\n",
    "        logger=wandb_logger,\n",
    "        max_epochs=100)\n",
    "    trainer.fit(lightning_module, train_dataloaders=data_module.train_dataloader(fold_idx), val_dataloaders=data_module.val_dataloader(fold_idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
